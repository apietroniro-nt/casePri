Guia de Testes – Case Cloud-Native AWS EKS (Fargate) e Simulação em Docker

1. Objetivo
Este documento descreve como testar os serviços (frontend, backend) localmente com Docker e em um cluster EKS (Fargate), incluindo verificação de saúde, criação/listagem de pedidos, testes de carga, caos, e observabilidade (Datadog, CloudWatch e opcionalmente Prometheus/Grafana).

2. Pré‑requisitos
- Docker Desktop em execução
- Conta AWS com permissões para EKS/ECR/IAM/DynamoDB (para testes no EKS)
- (Opcional) Chave do Datadog (DD_API_KEY) e site (DD_SITE) para enviar métricas/traços

3. Testes Locais (Docker)
3.1 Subir o ambiente
1) (Opcional) Exporte variáveis do Datadog para enviar dados:
   - bash
     export DD_API_KEY="<sua_api_key>"
     export DD_SITE="datadoghq.com"
   - PowerShell
     $env:DD_API_KEY="<sua_api_key>"
     $env:DD_SITE="datadoghq.com"
2) Suba os serviços:
   docker compose up -d --build

Containers:
- backend: API Node.js/Express em http://localhost:3000
- frontend: Nginx servindo build do React em http://localhost:5173
- dynamodb-local: Tabela "orders" criada automaticamente pelo init
- datadog-agent: Recebe logs/APM/DogStatsD (se DD_API_KEY/DD_SITE definidos, envia para Datadog)

3.2 Health check
- Backend: http://localhost:3000/healthz
  curl -sf http://localhost:3000/healthz

3.3 Criar e listar pedidos
- Criar pedido:
  curl -s -X POST http://localhost:3000/api/orders \
       -H "Content-Type: application/json" \
       -d '{"item":"book","price":10}'
- Listar pedidos:
  curl -s http://localhost:3000/api/orders

3.4 Métricas e Observabilidade (local)
- Prometheus metrics (backend): http://localhost:3000/metrics
- Datadog Agent local: recebe traços (APM), logs e DogStatsD do backend
  Observação: para enviar ao Datadog SaaS, defina DD_API_KEY e DD_SITE antes do compose.

3.5 Frontend
- Acesse http://localhost:5173 e crie/lista pedidos via UI

4. Testes no EKS (Fargate)
4.1 Provisionamento (executado via pipeline ou via container de ferramentas)
- Terraform cria VPC, EKS Fargate, ECR, DynamoDB, IRSA e Datadog Cluster Agent.
- Saídas importantes: backend_irsa_role_arn, dynamodb_table_name, ECR repos.

4.2 Deploy e Blue/Green
- O GitHub Actions (.github/workflows/cd.yml ou cicd.yml) faz:
  1) Build/push de imagens no ECR
  2) Deploy "green" a partir dos manifests base, espera rollout
  3) Troca o Service selector para color: green
  4) Limpa o "blue" após período de graça

4.3 Validações pós‑deploy
- Kube:
  ./scripts/kubectl.sh -n case get deploy,svc,pods
  ./scripts/kubectl.sh -n case rollout status deploy/backend-green --timeout=180s
- Health via Cluster (se ingress disponível):
  curl -sf http://<seu-host>/api/healthz  (ajuste conforme seu Ingress)

4.4 Caos (LitmusChaos)
- O pipeline instala o operador, aplica RBAC e executa o ChaosEngine (pod-delete) no backend.
- Verifica o ChaosResult (Pass/Fail) e imprime rollout/status pós‑caos.
- Para rodar manualmente via container de ferramentas:
  ./scripts/kubectl.sh apply -f k8s/litmus/litmus-rbac.yaml
  ./scripts/kubectl.sh apply -f k8s/litmus/backend-pod-delete-engine.yaml
  ./scripts/kubectl.sh -n case get chaosresults

4.5 Observabilidade (EKS)
- Datadog APM (agentless), métricas de cluster (Cluster Agent), logs via CloudWatch (ative integração AWS->Datadog)
- Opcional: Prometheus/Grafana (ENABLE_PROMETHEUS=true no repositório) para kube‑prometheus‑stack

5. Testes Automatizados
5.1 Backend (unitários)
- Em app/backend: npm test
  (CI executa automaticamente em PRs)

5.2 WireMock (Testcontainers)
- Teste: app/backend/tests/orders.wiremock.test.ts
- Requer Docker ativo (Testcontainers sobe WireMock temporário)
- Executar: npm test (na pasta do backend)

5.3 Teste de Carga (Locust)
- Arquivo: scripts/locustfile.py
- Instale localmente (opcional): pip install locust
- Execute com alvo local:
  locust -f scripts/locustfile.py --host http://localhost:3000
- Execute com alvo EKS (Ingress):
  locust -f scripts/locustfile.py --host http://<seu-host>

5.4 Caos adicional (script simples)
- scripts/chaos_kill_random_pod.py
- Requer: pip install kubernetes
- Exemplo:
  python scripts/chaos_kill_random_pod.py case app=backend

6. Painéis e Monitores (Datadog)
- Dashboards: observabilidade/datadog/dashboards/*
- Monitors: observabilidade/datadog/monitors/monitors.json
- Golden signals (latência, tráfego, erros, saturação) + métricas de negócio (orders.created/failed)

7. Critérios de Sucesso
- Local: healthz ok, criar/listar pedidos funcionam, /metrics acessível
- EKS: rollout verde bem‑sucedido, ChaosResult=Pass, serviços ok após o caos
- Observabilidade: traços no APM, métricas coletadas, logs no CloudWatch/Datadog

8. Troubleshooting Rápido
- Docker não sobe: abra Docker Desktop e aguarde “engine running”
- Frontend 5173 sem resposta: confirme mapeamento 5173:80 e logs do container
- Datadog sem dados: verifique DD_API_KEY/DD_SITE (local) e integração AWS (EKS)
- EKS Fargate: cheque permissões IAM, IRSA annotation do backend-sa e eventos do namespace

9. Comandos Úteis (via container de ferramentas)
- Construir imagem de ferramentas:
  docker compose -f docker-compose.tools.yml build tools
- Terraform:
  ./scripts/tf.sh init -input=false
  ./scripts/tf.sh plan -input=false
  ./scripts/tf.sh apply -input=false
- Kube:
  ./scripts/aws.sh eks update-kubeconfig --name "$EKS_CLUSTER_NAME" --region "$AWS_REGION"
  ./scripts/kubectl.sh -n case get pods

10. Contatos e Próximos Passos
- Adicionar NetworkPolicies e ingress controller por ambiente
- Habilitar mais experiments do Litmus (CPU, rede) e SLO probes
- Automatizar testes de carga em um job da pipeline pós‑deploy

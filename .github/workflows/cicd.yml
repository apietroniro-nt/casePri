name: CI-CD

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  AWS_REGION: ${{ vars.AWS_REGION }}
  AWS_ACCOUNT_ID: ${{ vars.AWS_ACCOUNT_ID }}
  EKS_CLUSTER_NAME: ${{ vars.EKS_CLUSTER_NAME }}
  DD_SITE: ${{ vars.DD_SITE || 'datadoghq.com' }}
  DDB_TABLE: ${{ vars.DDB_TABLE || 'orders' }}

permissions:
  id-token: write
  contents: read

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'push' }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Validate required variables
        run: |
          echo "Using variables:" \
            && echo "AWS_REGION=${{ env.AWS_REGION }}" \
            && echo "AWS_ACCOUNT_ID=${{ env.AWS_ACCOUNT_ID }}" \
            && echo "EKS_CLUSTER_NAME=${{ env.EKS_CLUSTER_NAME }}" \
            && echo "DD_SITE=${{ env.DD_SITE }}" \
            && echo "DDB_TABLE=${{ env.DDB_TABLE }}"
          missing=0
          [ -n "${{ env.AWS_REGION }}" ] || { echo "ERROR: AWS_REGION não definido (repo variables)."; missing=1; }
          [ -n "${{ env.EKS_CLUSTER_NAME }}" ] || { echo "ERROR: EKS_CLUSTER_NAME não definido (repo variables)."; missing=1; }
          [ -n "${{ secrets.AWS_ROLE_TO_ASSUME }}" ] || { echo "ERROR: secrets.AWS_ROLE_TO_ASSUME não definido."; missing=1; }
          if [ "$missing" -ne 0 ]; then exit 1; fi

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build and push backend image
        working-directory: app/backend
        run: |
          BACKEND_REPO=${{ steps.ecr.outputs.registry }}/backend
          IMAGE_TAG=${{ github.sha }}
          docker build -t $BACKEND_REPO:$IMAGE_TAG -t $BACKEND_REPO:latest .
          docker push $BACKEND_REPO:$IMAGE_TAG
          docker push $BACKEND_REPO:latest
          echo "BACKEND_IMAGE=$BACKEND_REPO:$IMAGE_TAG" >> $GITHUB_ENV

      - name: Build and push frontend image
        working-directory: app/frontend
        run: |
          FRONTEND_REPO=${{ steps.ecr.outputs.registry }}/frontend
          IMAGE_TAG=${{ github.sha }}
          docker build --build-arg VITE_BACKEND_URL=/api -t $FRONTEND_REPO:$IMAGE_TAG -t $FRONTEND_REPO:latest .
          docker push $FRONTEND_REPO:$IMAGE_TAG
          docker push $FRONTEND_REPO:latest
          echo "FRONTEND_IMAGE=$FRONTEND_REPO:$IMAGE_TAG" >> $GITHUB_ENV

      - name: Update kubeconfig
        run: aws eks update-kubeconfig --name "$EKS_CLUSTER_NAME" --region "$AWS_REGION"

      - name: Prepare namespace and config
        run: |
          kubectl apply -f k8s/namespace.yaml
          sed -e "s/<AWS_REGION>/${AWS_REGION}/g" \
              -e "s/orders/${DDB_TABLE}/g" \
              -e "s/datadoghq.com/${DD_SITE}/g" k8s/env-config.yaml | kubectl apply -f -
          # Datadog secret
          sed -e "s/<DD_API_KEY>/${{ secrets.DD_API_KEY }}/g" k8s/datadog-secret.yaml | kubectl apply -f -
          # ServiceAccount with IRSA annotation
          sed -e "s#<BACKEND_IRSA_ROLE_ARN>#${{ secrets.BACKEND_IRSA_ROLE_ARN }}#g" k8s/backend-serviceaccount.yaml | kubectl apply -f -

      - name: Deploy blue (initial) if missing
        run: |
          set -e
          # Apply base manifests with blue color labels
          sed -e "s#<AWS_ACCOUNT_ID>#${AWS_ACCOUNT_ID}#g" -e "s#<AWS_REGION>#${AWS_REGION}#g" \
              k8s/backend-deployment.yaml | kubectl apply -f -
          sed -e "s#<AWS_ACCOUNT_ID>#${AWS_ACCOUNT_ID}#g" -e "s#<AWS_REGION>#${AWS_REGION}#g" \
              k8s/frontend-deployment.yaml | kubectl apply -f -
          kubectl apply -f k8s/ingress.yaml

      - name: Create green deployments
        run: |
          set -e
          # Backend green
          sed -e "s/name: backend$/name: backend-green/" \
              -e "s/app: backend$/app: backend\n    color: green/" \
              -e "s/color: blue/color: green/g" \
              -e "s#<AWS_ACCOUNT_ID>#${AWS_ACCOUNT_ID}#g" -e "s#<AWS_REGION>#${AWS_REGION}#g" \
              -e "s#image: .*$#image: ${BACKEND_IMAGE}#" \
              k8s/backend-deployment.yaml | kubectl apply -f -

          # Frontend green
          sed -e "s/name: frontend$/name: frontend-green/" \
              -e "s/app: frontend$/app: frontend\n    color: green/" \
              -e "s/color: blue/color: green/g" \
              -e "s#<AWS_ACCOUNT_ID>#${AWS_ACCOUNT_ID}#g" -e "s#<AWS_REGION>#${AWS_REGION}#g" \
              -e "s#image: .*$#image: ${FRONTEND_IMAGE}#" \
              k8s/frontend-deployment.yaml | kubectl apply -f -

      - name: Wait for green rollout
        run: |
          kubectl -n case rollout status deploy/backend-green --timeout=180s
          kubectl -n case rollout status deploy/frontend-green --timeout=180s

      - name: Switch services to green
        run: |
          kubectl -n case patch svc/backend -p '{"spec":{"selector":{"app":"backend","color":"green"}}}'
          kubectl -n case patch svc/frontend -p '{"spec":{"selector":{"app":"frontend","color":"green"}}}'

      - name: Verify health
        run: |
          # Replace case.local with your Ingress host or use port-forwarding in non-prod
          echo "Switched services to green"

      - name: Cleanup old blue after grace period
        if: ${{ success() }}
        run: |
          sleep 10
          kubectl -n case delete deploy backend --ignore-not-found=true || true
          kubectl -n case delete deploy frontend --ignore-not-found=true || true

      - name: Install LitmusChaos (operator) if missing
        run: |
          kubectl get ns litmus >/dev/null 2>&1 || kubectl create ns litmus
          kubectl apply -f https://litmuschaos.github.io/litmus/litmus-operator-v3.yaml

      - name: Install pod-delete experiment from LitmusHub
        run: |
          kubectl -n litmus apply -f "https://hub.litmuschaos.io/api/chaos/3.6.0?file=charts/generic/pod-delete/experiment.yaml"

      - name: Configure Litmus RBAC in target namespace
        run: |
          kubectl apply -f k8s/litmus/litmus-rbac.yaml

      - name: Run backend pod-delete ChaosEngine
        run: |
          kubectl apply -f k8s/litmus/backend-pod-delete-engine.yaml
          echo "Waiting for ChaosResult verdict..."
          for i in {1..60}; do
            verdict=$(kubectl -n case get chaosresult backend-pod-delete -o jsonpath='{.status.experimentStatus.verdict}' 2>/dev/null || echo "")
            if [ "$verdict" = "Pass" ] || [ "$verdict" = "Fail" ]; then
              echo "Chaos verdict: $verdict"; break; fi; sleep 10; done
          kubectl -n case get pods -l app=backend -o wide || true
          kubectl -n case describe chaosengine backend-pod-delete || true
          if [ "$verdict" = "Fail" ] || [ -z "$verdict" ]; then
            echo "Chaos test did not pass"; exit 1; fi

      - name: Optional Prometheus install (set ENABLE_PROMETHEUS=true)
        if: ${{ vars.ENABLE_PROMETHEUS == 'true' }}
        run: |
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo update
          helm upgrade --install kps prometheus-community/kube-prometheus-stack -n monitoring --create-namespace
